{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# This file is to finish the udacity nano degree problem for Anna_KaRNNa with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This file is to build a chracter-wise RNN trained on Anna Kerenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt','r') as f:\n",
    "    text = f.read()\n",
    "vocab =sorted(set(text))\n",
    "vocab_to_int = {c: i for i,c in enumerate(vocab)}\n",
    "int_to_vocab =dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One of the best first line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Make training mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Follow the udacity's books function to create the batch-iterator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, n_steps):\n",
    "    ''' Create generator that returns the batches of size \n",
    "        batch_size * n_steps\n",
    "        Here we follow the udacity's notebook's rule, we will remove the last piece\n",
    "        of the samples smaller than the batch_size.\n",
    "    '''\n",
    "    size = batch_size * n_steps\n",
    "    n_batches = len(arr)/size\n",
    "    \n",
    "    # Here we only keep enough numbers \n",
    "    arr = arr[:size*n_batches]\n",
    "    \n",
    "    # reshape batches into batch_size row\n",
    "    arr = arr.reshape((batch_size,-1))\n",
    "    \n",
    "    for n in range(0,arr.shape[1],n_steps):\n",
    "        x = arr[:,n:n+n_steps]\n",
    "        y_temp = arr[:,n+1:n+n_steps+1]\n",
    "        \n",
    "        # for the last batch, the y will be short with one.\n",
    "        # we will pad the last value with 0\n",
    "        \n",
    "        y = np.zeros(x.shape)\n",
    "        y[:,:y_temp.shape[1]]=y_temp\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x \\n', array([[31, 64, 57, 72, 76, 61, 74,  1, 16,  0],\n",
      "       [ 1, 57, 69,  1, 70, 71, 76,  1, 63, 71],\n",
      "       [78, 65, 70, 13,  0,  0,  3, 53, 61, 75],\n",
      "       [70,  1, 60, 77, 74, 65, 70, 63,  1, 64],\n",
      "       [ 1, 65, 76,  1, 65, 75, 11,  1, 75, 65],\n",
      "       [ 1, 37, 76,  1, 79, 57, 75,  0, 71, 70],\n",
      "       [64, 61, 70,  1, 59, 71, 69, 61,  1, 62],\n",
      "       [26,  1, 58, 77, 76,  1, 70, 71, 79,  1],\n",
      "       [76,  1, 65, 75, 70,  7, 76, 13,  1, 48],\n",
      "       [ 1, 75, 57, 65, 60,  1, 76, 71,  1, 64]]))\n",
      "('\\n y \\n', array([[64., 57., 72., 76., 61., 74.,  1., 16.,  0.,  0.],\n",
      "       [57., 69.,  1., 70., 71., 76.,  1., 63., 71., 65.],\n",
      "       [65., 70., 13.,  0.,  0.,  3., 53., 61., 75., 11.],\n",
      "       [ 1., 60., 77., 74., 65., 70., 63.,  1., 64., 65.],\n",
      "       [65., 76.,  1., 65., 75., 11.,  1., 75., 65., 74.],\n",
      "       [37., 76.,  1., 79., 57., 75.,  0., 71., 70., 68.],\n",
      "       [61., 70.,  1., 59., 71., 69., 61.,  1., 62., 71.],\n",
      "       [ 1., 58., 77., 76.,  1., 70., 71., 79.,  1., 75.],\n",
      "       [ 1., 65., 75., 70.,  7., 76., 13.,  1., 48., 64.],\n",
      "       [75., 57., 65., 60.,  1., 76., 71.,  1., 64., 61.]]))\n"
     ]
    }
   ],
   "source": [
    "print('x \\n', x[:10, :10])\n",
    "print('\\n y \\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here we build the LSTM neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Need to rewrite this function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM_Char(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_dim,n_steps,n_layers,label_size,batch_size,drop_out=0.5,lr=0.001):\n",
    "        \n",
    "        super(LSTM_Char,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.label_size = label_size\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(input_size= label_size ,hidden_size = hidden_dim,num_layers = n_layers,\\\n",
    "                            dropout=drop_out,batch_first=True)\n",
    "        self.hidden = self.init_hidden(n_steps)\n",
    "        self.out = nn.Linear(hidden_dim,label_size)\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_hidden(self,n_seqs):\n",
    "        ## Two layer of hidden, first is for the input x, second is for the hidden state\n",
    "        weight = next(self.parameters()).data\n",
    "        return (Variable(weight.new(self.n_layers,n_seqs,self.hidden_dim).zero_()),\n",
    "                Variable(weight.new(self.n_layers,n_seqs,self.hidden_dim).zero_()))\n",
    "    \n",
    "    def forward(self,x,hc):\n",
    "        # Here we put the hc in the tuple\n",
    "        x,(h,c) = self.lstm(x,hc)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Put all the LSTM outputs together\n",
    "        x = x.view(x.size()[0]*x.size()[1],self.n_hidden)\n",
    "        \n",
    "        return x,(h,c)\n",
    "    \n",
    "    def predict(self,char,h=None,cuda=False,top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Return the predicted character and the hidden state.\n",
    "        '''\n",
    "        # Currently we don't consider cuda here.\n",
    "        if h is None:\n",
    "            h=self.init_hidden(1)\n",
    "        x = np.array(vocab_to_int[char])\n",
    "        x = one_hot_encode(x,self.label_size)\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(x),volatile = True)\n",
    "        \n",
    "        h = tuple(Variable(each.data,volatile = True) for each in h)\n",
    "        \n",
    "        out,h= self.forward(inputs,h)\n",
    "        \n",
    "        p = F.softmax(out).data\n",
    "        \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(self.label_size)\n",
    "        else:\n",
    "            p,top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        p = p.numpy().squeeze()\n",
    "        \n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        return int_to_vocab[char],h\n",
    "    \n",
    "    def init_weight(self):\n",
    "        initrange = 0.1\n",
    "        #set bias tensor to all zeros\n",
    "        self.out.bias.data.fill_(0)\n",
    "        # set weight to randeom uniform\n",
    "        self.out.weight.data.uniform_(-1,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = LSTM_Char(hidden_dim = 512,n_steps=100,\\\n",
    "                n_layers = 2,label_size = len(vocab),\\\n",
    "                batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "opt = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we can do the split between training and test data\n",
    "val_frac = 0.2\n",
    "val_index = int(len(encoded)*(1-val_frac))\n",
    "data,val_data = encoded[:val_index],encoded[val_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clip = 5\n",
    "counter = 0\n",
    "for e in range(epoch):\n",
    "    h = net.init_hidden(n_seqs)\n",
    "    for x, y in get_batches(data,n_seqs,n_steps):\n",
    "        counter += 1\n",
    "        \n",
    "        # Need to do one-hot encoding and make them the torch tensors\n",
    "        x = one_hot_encode(x,label_size)\n",
    "        x, y =torch.from_numpy(x),torch.from_numpy(y)\n",
    "        \n",
    "        inputs,targetss = Variable(x), Variable(y)\n",
    "        \n",
    "        # Create new variables for the hidden state, otherwise we'd backprop\n",
    "        # thourgh the entire training history\n",
    "        ## Need to double check which options works better, detach or create new variables\n",
    "        \n",
    "        h = tuple([Variable(each.data) for each in h])\n",
    "        \n",
    "        net.zero_grad()\n",
    "        \n",
    "        output, h = net.forward(inputs,h)\n",
    "        \n",
    "        loss = criterion(output,targets.view(n_seqs*n_steps))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # clip_grad_norm helps prevent the exploding gradient\n",
    "        # double check this\n",
    "        nn.utils.clip_grad_norm(net.parameters,clip)\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(n_seqs)\n",
    "            val_losses = []\n",
    "            for x, y in get_batches(val_data,n_seqs,n_steps):\n",
    "                x = one_hot_encode(x,label_size)\n",
    "                x,y = torch.from_numpy(x),torch.from_numpy(y)\n",
    "                \n",
    "                val_h = tuple([Variable(each.data,volatile= True) for each in val_h ])\n",
    "                \n",
    "                inputs, targets = Variable(x,volatile=True),Variable(y,volatile=True)\n",
    "                \n",
    "                output,val_h = net.forward(inputs,val_h)\n",
    "                \n",
    "                val_loss = criterion(output,targets.view(n_seqs*n_steps))\n",
    "                \n",
    "                val_losses.append(val_loss.data[0])\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.data[0]),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
