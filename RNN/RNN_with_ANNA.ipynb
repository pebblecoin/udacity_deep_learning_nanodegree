{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# This file is to finish the udacity nano degree problem for Anna_KaRNNa with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This file is to build a chracter-wise RNN trained on Anna Kerenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt','r') as f:\n",
    "    text = f.read()\n",
    "vocab =sorted(set(text))\n",
    "vocab_to_int = {c: i for i,c in enumerate(vocab)}\n",
    "int_to_vocab =dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One of the best first line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Make training mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Follow the udacity's books function to create the batch-iterator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns mini-batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "    '''\n",
    "    \n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def get_batches(arr, batch_size, n_steps):\n",
    "#     ''' Create generator that returns the batches of size \n",
    "#         batch_size * n_steps\n",
    "#         Here we follow the udacity's notebook's rule, we will remove the last piece\n",
    "#         of the samples smaller than the batch_size.\n",
    "#     '''\n",
    "#     size = batch_size * n_steps\n",
    "#     n_batches = len(arr)/size\n",
    "    \n",
    "#     # Here we only keep enough numbers \n",
    "#     arr = arr[:size*n_batches]\n",
    "    \n",
    "#     # reshape batches into batch_size row\n",
    "#     arr = arr.reshape((batch_size,-1))\n",
    "    \n",
    "#     for n in range(0,arr.shape[1],n_steps):\n",
    "#         x = arr[:,n:n+n_steps]\n",
    "#         y_temp = arr[:,n+1:n+n_steps+1]\n",
    "        \n",
    "#         # for the last batch, the y will be short with one.\n",
    "#         # we will pad the last value with 0\n",
    "        \n",
    "#         y = np.zeros(x.shape)\n",
    "#         y[:,:y_temp.shape[1]]=y_temp\n",
    "        \n",
    "#         yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_seqs = 128\n",
    "n_steps = 100\n",
    "label_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x \\n', tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 1.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]))\n",
      "('\\n y \\n', tensor([[ 64,  57,  72,  76,  61,  74,   1,  16,   0,   0],\n",
      "        [  1,  58,  71,  60,  81,   1,  71,  62,   1,  64],\n",
      "        [  1,  76,  71,   1,  69,  61,  27,   1,  37,   1],\n",
      "        [ 57,  76,   1,  57,   1,  63,  77,  65,  68,  76],\n",
      "        [ 61,  69,  58,  61,  74,  65,  70,  63,   1,  76],\n",
      "        [ 71,  78,  65,  76,  59,  64,  11,   1,  79,  64],\n",
      "        [ 62,  71,  74,   1,  76,  61,  70,   1,  81,  61],\n",
      "        [ 65,  70,  75,   1,  57,  74,  61,   1,  75,  57],\n",
      "        [  1,  81,  71,  77,   1,  76,  71,   1,  57,  59],\n",
      "        [ 76,  65,  71,  70,   1,  71,  62,   1,  57,   1]]))\n"
     ]
    }
   ],
   "source": [
    "print('x \\n', x[:10, :10])\n",
    "print('\\n y \\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here we build the LSTM neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Need to rewrite this function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM_Char(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_dim,n_steps,n_layers,label_size,batch_size,drop_out=0.5,lr=0.001):\n",
    "        \n",
    "        super(LSTM_Char,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.label_size = label_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_out = drop_out\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "        self.lstm = nn.LSTM(input_size= label_size ,hidden_size = hidden_dim,num_layers = n_layers,\\\n",
    "                            dropout=drop_out,batch_first=True)\n",
    "        self.hidden = self.init_hidden(n_steps)\n",
    "        self.out = nn.Linear(hidden_dim,label_size)\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_hidden(self,n_seqs):\n",
    "        ## Two layer of hidden, first is for the input x, second is for the hidden state\n",
    "        weight = next(self.parameters()).data\n",
    "        return (Variable(weight.new(self.n_layers,n_seqs,self.hidden_dim).zero_()),\n",
    "                Variable(weight.new(self.n_layers,n_seqs,self.hidden_dim).zero_()))\n",
    "    \n",
    "    def forward(self,x,hc):\n",
    "        # Here we put the hc in the tuple\n",
    "        x,(h,c) = self.lstm(x,hc)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Put all the LSTM outputs together\n",
    "        x = x.view(x.size()[0]*x.size()[1],self.hidden_dim)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x,(h,c)\n",
    "    \n",
    "    def predict(self,char,h=None,cuda=False,top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Return the predicted character and the hidden state.\n",
    "        '''\n",
    "        # Currently we don't consider cuda here.\n",
    "        if h is None:\n",
    "            h=self.init_hidden(1)\n",
    "        x = np.array([[vocab_to_int[char]]])\n",
    "\n",
    "        x = one_hot_encode(x,self.label_size)\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(x),volatile = True)\n",
    "        \n",
    "        h = tuple(Variable(each.data,volatile = True) for each in h)\n",
    "        \n",
    "        out,h= self.forward(inputs,h)\n",
    "        \n",
    "        p = F.softmax(out).data\n",
    "        \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(self.label_size)\n",
    "        else:\n",
    "            p,top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "            \n",
    "        p = p.numpy().squeeze()\n",
    "\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "\n",
    "        return int_to_vocab[char],h\n",
    "    \n",
    "    def init_weight(self):\n",
    "        initrange = 0.1\n",
    "        #set bias tensor to all zeros\n",
    "        self.out.bias.data.fill_(0)\n",
    "        # set weight to randeom uniform\n",
    "        self.out.weight.data.uniform_(-1,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    \n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((arr.shape[0],arr.shape[1], n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = LSTM_Char(hidden_dim = 512,n_steps=100,\\\n",
    "                n_layers = 2,label_size = len(vocab),\\\n",
    "                batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "opt = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here we can do the split between training and test data\n",
    "val_frac = 0.2\n",
    "val_index = int(len(encoded)*(1-val_frac))\n",
    "data,val_data = encoded[:val_index],encoded[val_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3945)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-f0026e0a03cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# clip_grad_norm helps prevent the exploding gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/edwin/anaconda/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/edwin/anaconda/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "clip = 5\n",
    "counter = 0\n",
    "print_every = 10\n",
    "for e in range(epoch):\n",
    "    h = net.init_hidden(n_seqs)\n",
    "    for x, y in get_batches(data,n_seqs,n_steps):\n",
    "        counter += 1\n",
    "        \n",
    "        # Need to do one-hot encoding and make them the torch tensors\n",
    "        x = one_hot_encode(x,label_size)\n",
    "        x, y =torch.from_numpy(x),torch.from_numpy(y)\n",
    "        \n",
    "        inputs,targets = Variable(x), Variable(y)\n",
    "        \n",
    "        # Create new variables for the hidden state, otherwise we'd backprop\n",
    "        # thourgh the entire training history\n",
    "        ## Need to double check which options works better, detach or create new variables\n",
    "        \n",
    "        h = tuple([Variable(each.data) for each in h])\n",
    "        \n",
    "        net.zero_grad()\n",
    "        \n",
    "        output, h = net.forward(inputs,h)\n",
    "        \n",
    "        loss = criterion(output,targets.view(n_seqs*n_steps))\n",
    "        \n",
    "        print loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # clip_grad_norm helps prevent the exploding gradient\n",
    "        # double check this\n",
    "        nn.utils.clip_grad_norm(net.parameters(),clip)\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(n_seqs)\n",
    "            val_losses = []\n",
    "            for x, y in get_batches(val_data,n_seqs,n_steps):\n",
    "                x = one_hot_encode(x,label_size)\n",
    "                x,y = torch.from_numpy(x),torch.from_numpy(y)\n",
    "                \n",
    "                val_h = tuple([Variable(each.data,volatile= True) for each in val_h ])\n",
    "                \n",
    "                inputs, targets = Variable(x,volatile=True),Variable(y,volatile=True)\n",
    "                \n",
    "                output,val_h = net.forward(inputs,val_h)\n",
    "                \n",
    "                val_loss = criterion(output,targets.view(n_seqs*n_steps))\n",
    "                \n",
    "                val_losses.append(val_loss.data[0])\n",
    "                \n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.4f}...\".format(loss.data[0]),\n",
    "                  \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(net, size, prime='The', top_k=None, cuda=False):\n",
    "        \n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = net.predict(ch, h, cuda=cuda, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = net.predict(chars[-1], h, cuda=cuda, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 2000\n",
    "prime='Anna'\n",
    "top_k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwin/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:53: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/edwin/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/edwin/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "chars = [ch for ch in prime]\n",
    "h = net.init_hidden(1)\n",
    "for ch in prime:\n",
    "    char, h = net.predict(ch, h, cuda=False, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwin/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:53: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/edwin/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/edwin/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna0i@N!!(0i/pQNi@!:NpdJgi60roij)fH0Hn0H&i@Q;,piiiBQ,zQH0i?&Qg(Ai!d!A(0Z!ox(g@!i!ii0(i(((HH/iQJ*?w(oaiooO!zK)(0(HH!0&3)zix0HKH&Q(yniKvs0!xiZoQQ0(K&_*I?i`a-Q((wi!K(LA)@&JHpngixiJKH(!,*oi(ii0&0&H3ixgoow(0iioii0(3,(i(Ni,)((),)00cs&(@!0-Hi!Q(Qii)QQ0na0(ii!0(HiwK-H(0IK0(iNwlK(0(H0,(NikHHi0!0)g-c!i,!!soiHwi)0mH!0:N(i0elXH`dBdok0Ve0H*N!0(!J00*gH0V!%!(x0x(d(i(Q1ah0H,iii-oN?(iylQYi6&Qi((H0(00noiH0HoHiz,Ni?g(e!di-0HHQ*O:p1z(xi43H:Qx:N(iOI:gi3)he(Zio!HiciglwQ&rokHaidek00HoQ_3nQxHgiih(&p(I!Q&@w!@ONiY!o,(Ni1y!i)(KV00(-Q)*(&(y@0gg0KQiQii!NY(l0wzlQ,ix$xQ@iN&xiKl0x0iioH&e,:ix,w(iNQ0(H?IgN,-?,QN!QdiN?coho:e@!KH0ci0enQNiJ)liNig0i-KHiV!)iQ)8Qg0Q0on0(H,6QB2ii0xo(01@)0QV8o(0Q)HiQgHiHSiK3o0wKQOinw?B@6QicQNigeQH0OQfQ)0iiii&QK0oHx-(0N@A-NyLiip!!iz0z9!@iiH0?(N/!9?1)0(OoQci0?K0iH0QQl((gg)oHN)QHQ)*0H-((0(0i-QNQALNQ&zo-0Q(?i8xIQyx(0(QNH&iQcAR)s0@i(-?i0h-Lc(idNw;0hIwNH0L!LQ!V!N*e:0)ixi)pBHi?cOI(Kwwow_,0izK06(i!)idQHgQs&0\n",
      "0dn0(9(oi0)0Nx(t(eQQpH0i*Qcio(&HJ_)(NzkHig@3Nxio0?Qod:(,kHnX!603(AgQNHrBk:!&wQ*iE108Qio?()i)Qh!Q)0NoQQ(Qo((in0Q0tnep0(i!!(00)it0)k@1Axp(0iQ@0--(!i?*(io!&(0!!Hc)iAQi(0oi0i,Q*Ai)iQ@@6iiii)8ge)x0HixNNQ)xaN?0iNQx*Q0xi)&$-iH$iz)HQ!ii&N)aH-8i0(*?n(?QnQd!?QHw0@yr(!Q1xr3)Am&0(h*N(i?g!xiZQ,i!diQK8igLo*(0ii((ioI((Ni&i0i*Qpiwgdd(*0))6ign-HHe,Q@0)0Qdwi0(i!i?iIB(,i(Qc(0*p0)(*H?@e:Nirn)s((iIhg(*Qa(ipo,oigQN0de?)zLQQQ*)niNkoHQ\n",
      "&!0i(NQ,?,N,QaQH0iQ1OiH1w&0/iQQ0kKJozz:-J0QQwpQ!06i0Hk0n!,6iH0cQ0!QN!N!0HH&QA*if!KAQ?0zgkiN0(QN(H-iQ?;B00H0QHe((:cioQA(!(QLiiTi-N(,i,HN:Ni0&HHQ00AKN0Hi!icxR!(*!iL)8H!iQ?wxi/pn(0(3ic!&0!iHig(o!iKiH((J(xdxtQ0HQ0:%0oh(r),i_cow(!N,)*-!oiz(I0))NiHg6QO)x10Q(1-zKl-h0Qi0Nd&Qi?((Ae*0!oNi-QQzHNHIiQi!&QN0Q&(:NH(&z0)@-&!8h*xxhigihZQ3,0NaQH\n",
      "3Qi!!(!Ne0wpii0(8o00Qi0i0i,Hk!iNi(OHH0ig*(wiil,n0/(&IkNNiH-)0:i0f;Kwiz0iHoi&!Yw(a&&&@i(HiNHiei5N3QH)KQHi(w0&Q&00aHiQi(gx(1wi(i!iwii?,oe((xh?QiNoQo&KONQZw*,c3$iJw3H!0ra0!:en?\n",
      "di(ih3H1_0pe)Q!0o(i00in)i0)Qt!(z(HgQHdwi:HQ,iex0iQ&8,i*)0o0(QHi)iBn0Qo000Vdi0I0@p-10(:pN-Q&l0_N!Qi-Qi(i-0dki@QHNg0aNH0i5Q(iJv0wlpw:i0,QAo900!&&wN!0!!i0LQ&pN0(O:Ni!oii0oHHini0Nziiii!i&K(:gdEi-@iQR*KsHHHxi06iN8QN*Q&(h0$o&Z!HNci&ionHA,iinwQ(N)f!iiNi!&e@iQhi0L1N,Q!)Qxin)$gH0!!(QHN(no!xHxc:Q0Qi0Q!iHNHi*0(!i)Q`oOi;k)(QhOg&NiN()h!08YgiwinK&xHzi0HiK!!wee)iiiii(*J,-i-H!ii0(0KiN&BipHH0d&(-!(&6a8gHc?!/i0AgQ!?i@i0K(dicQ(!f-iiOi0lii*?ic!QY3N(d?oH!(0i*a)(z!ii(N(eQ8QKIx*)i)inQQ0\n",
      ",itH!iQnBQQincL0Q&ow!)10z(!ifiisii0_dNNn((?@0i$i(lI0xw0(i0zQH!?Q0@0Qiw0()Q(3K6iK-QH:o_@0eiNiiIQ)nwK30@in!lNi0e(8HkHnH6x,lOo8kA?eo0KNoN0iN@iK9p!@QHI?oiLH:QH&0N(0(aH1*Q!rHy000ii((Y)NQ)iiLih0iiN0wiH,MiHgDziiizi-fH0Ki0ic0L!@yin@i)0&Q)iOKN0AtQk((iiQ0-yi(!iQ(NN!riieA;Hi6((rcl0?-iQHBNhHi&QiQiir*x0c!g(H\n",
      "gii0i(i!0H&i0&xiQo(HQxH-iHNkhd(RN!()Ai1iIHQA0iQiHN0(gi(Hiipi-oiQx0((*ix:*o(Q!(0e0!1(!0fd0e@xHQiH&!aeH,)ilx(;Qi0iQNON(Q0HiehH/:QN(xNaQJnzHl0(ZlkBg0Q&(y:Q(HN)@N,iewipQiN(!si)K(N000HiQH(idih@(HiQQQpo(Q()01iH(ng(1iz;e,kQH@HH60QOHN(xK!K(i(H?QHQN)(0&i0yiH00QepfJii0dKw(x0(orm(Q0cdiiQHH,lioz)(nKiOcnQKz)wi0,QiH-niOcN(1x0(!d*d(&!NQQ0Qcr:ii,0)0igf_igcNkpXii6(H10iN&i0 !!x0iBpiHiQaH0Qf6:pQ0Nzo(Q*(?))(0H!!60)o&(eeif@Qc:Hio!Q:QB0Bi(8-(8!0(*0igQQ)H0Q:!(c0xx:Kti:(()k80x(l)ci!ng-ipxKNwi00QiidQ&iKVHN00ie0L!()Qih(Hwgo0(!Q(NA0NQ6llN&@?ieBixwi*wei)O(in0!(oi&&KVnMixQ0i)(?LQ?giwA!w0)HiY)iaK!IN(30!Q000QHQ-NQx!H-!!?h(xYINzNiJ))1niiN((&i(?!(N,ig!ii!N!ao(N!aNQ?4i!g)i!ir(!!cgHK1nNi!xN,0&iciIgi((00Q0!1Ng!aAii0iiJ(Hile?Q0(Q`lQeNizih0ng)i&nQNini1Q&`HQI,i80\n",
      "@!oegxi0m!wiH?*&0Qii6fViHgkaQ0ew!0hO-nx(,3Qii0QgNB?iQi0iQHiN)-HQH(@Bh-eh!-Q(Qwoi!wn(g)(iQi(ixnAi(iNi:!N,(A(QI0Hi(&-,iirQ*(ziQH,i-(8Qn(iAhgxwN*(*nQcpg0iV00!0QHdNNNnQy(o?!YA00iaKii(ni:0i0(icfizii!isQhNQ&QQ!(iQi!HO$aH!HNQ(1Hi0B(on0((0i`0?N$i$N@L(:l)f(&iN)iHkigQHiiQ)Qp0)hwQ!Q&izpzi0zxNHQk&I!(I,QOi0ii0H5,x,00e(H(icH!Qpik0iiii&&c0?&)!)iQ0x!&0x!0iQQ0N)n!/?wo)o(i&LoQQ(i&Ii!Niiw!!Q0Vohi@N&@iiiHA,i08x0\n",
      "Kg!i(Q!*i0!H!inz!aki(Ayii((8iZQH!hO?ti(siH-IH&I0)(QH0!IQz0Q8pQ--z,10wii?NBH(g0Y0:0QiOfQQ\n",
      "a0QN00N)Y(!(iii080$3iQJiioai?(c!wNHKcii0)si!Nxii(@0Oi(iQki&o\n",
      "H,t0!!(i(i&(0,-k@tQL@ci0xH,!NiQc!(-s0@!kHiinix/((H0w&pHJkiHHNi(Jiri!gNH@,ii(!H0-Nn1xiQQV(0(eH6iJQ%i,Y0@paxz&,0KQd)oN0_0igg`-K-Q,gQoa\n"
     ]
    }
   ],
   "source": [
    "chars.append(char)\n",
    "\n",
    "# Now pass in the previous character and get a new one\n",
    "for ii in range(size):\n",
    "    char, h = net.predict(chars[-1], h, cuda=False, top_k=top_k)\n",
    "    chars.append(char)\n",
    "\n",
    "print ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
